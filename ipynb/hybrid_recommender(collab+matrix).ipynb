{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8048ab34",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymongo in c:\\users\\tuanb\\anaconda3\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in c:\\users\\tuanb\\anaconda3\\lib\\site-packages (from pymongo) (2.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "979bb48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2ea587f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(\"mongodb+srv://baosurgeous:testDatabase@testcluster.dfxfjru.mongodb.net/?\")\n",
    "db = client[\"moviesDB\"]\n",
    "movies_collection = db[\"movies\"]\n",
    "ratings_collection = db[\"ratings\"]\n",
    "users_collection = db[\"users\"]\n",
    "\n",
    "def convert_collection_to_pandas_dataframe(collection):\n",
    "    # Retrieve data from MongoDB\n",
    "    data_from_mongo = collection.find({}, {\"_id\": 0})\n",
    "\n",
    "    # Convert data to a list of dictionaries\n",
    "    data_list = list(data_from_mongo)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(data_list)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "movies_df = convert_collection_to_pandas_dataframe(movies_collection)\n",
    "ratings_df = convert_collection_to_pandas_dataframe(ratings_collection)\n",
    "users_df = convert_collection_to_pandas_dataframe(users_collection)## Divide the ratings data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66aeeb98",
   "metadata": {},
   "source": [
    "## Divide the ratings data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e478bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(df, test_size=0.1):\n",
    "    train_set, test_set = pd.DataFrame(), pd.DataFrame()\n",
    "    unique_users = ratings_df['user_id'].unique()\n",
    "\n",
    "    for user in unique_users:\n",
    "        user_data = df[df['user_id'] == user]\n",
    "        train_user, test_user = train_test_split(user_data, test_size=test_size, random_state=42)\n",
    "\n",
    "        train_set = pd.concat([train_set, train_user])\n",
    "        test_set = pd.concat([test_set, test_user])\n",
    "\n",
    "    return train_set, test_set\n",
    "\n",
    "rating_train, rating_test = split_data(ratings_df, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcb13f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_train = rating_train.values\n",
    "rate_test = rating_test.values\n",
    "\n",
    "# # indices start from 0\n",
    "rate_train[:, :2] -= 1\n",
    "rate_test[:, :2] -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e13bafa",
   "metadata": {},
   "source": [
    "## Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5281132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "class CF(object):\n",
    "    \"\"\"docstring for CF\"\"\"\n",
    "    def __init__(self, Y_data, k, dist_func = cosine_similarity, uuCF = 1):\n",
    "        self.uuCF = uuCF # user-user (1) or item-item (0) CF\n",
    "        self.Y_data = Y_data if uuCF else Y_data[:, [1, 0, 2]]\n",
    "        self.k = k # number of neighbor points\n",
    "        self.dist_func = dist_func\n",
    "        self.Ybar_data = None\n",
    "        # number of users and items. Remember to add 1 since id starts from 0\n",
    "        self.n_users = int(np.max(self.Y_data[:, 0])) + 1\n",
    "        self.n_items = int(np.max(self.Y_data[:, 1])) + 1\n",
    "        self.items_id = [int(item) for item in np.unique(self.Y_data[:, 1])]\n",
    "\n",
    "    def add(self, new_data):\n",
    "        \"\"\"\n",
    "        Update Y_data matrix when new ratings come.\n",
    "        For simplicity, suppose that there is no new user or item.\n",
    "        \"\"\"\n",
    "        self.Y_data = np.concatenate((self.Y_data, new_data), axis = 0)\n",
    "\n",
    "    def normalize_Y(self):\n",
    "        users = self.Y_data[:, 0] # all users - first col of the Y_data\n",
    "        self.Ybar_data = self.Y_data.copy()\n",
    "        self.mu = np.zeros((self.n_users,))\n",
    "        for n in range(self.n_users):\n",
    "            # row indices of rating done by user n\n",
    "            # since indices need to be integers, we need to convert\n",
    "            ids = np.where(users == n)[0].astype(np.int32)\n",
    "            # indices of all ratings associated with user n\n",
    "            item_ids = self.Y_data[ids, 1]\n",
    "            # and the corresponding ratings\n",
    "            ratings = self.Y_data[ids, 2]\n",
    "            # take mean\n",
    "            m = np.mean(ratings)\n",
    "            if np.isnan(m):\n",
    "                m = 0 # to avoid empty array and nan value\n",
    "            # normalize\n",
    "            self.Ybar_data[ids, 2] = ratings - self.mu[n]\n",
    "\n",
    "        ################################################\n",
    "        # form the rating matrix as a sparse matrix. Sparsity is important\n",
    "        # for both memory and computing efficiency. For example, if #user = 1M,\n",
    "        # #item = 100k, then shape of the rating matrix would be (100k, 1M),\n",
    "        # you may not have enough memory to store this. Then, instead, we store\n",
    "        # nonzeros only, and, of course, their locations.\n",
    "        self.Ybar = sparse.coo_matrix((self.Ybar_data[:, 2],\n",
    "            (self.Ybar_data[:, 1], self.Ybar_data[:, 0])), (self.n_items, self.n_users))\n",
    "        self.Ybar = self.Ybar.tocsr()\n",
    "\n",
    "    def similarity(self):\n",
    "        self.S = self.dist_func(self.Ybar.T, self.Ybar.T)\n",
    "\n",
    "    def refresh(self):\n",
    "        \"\"\"\n",
    "        Normalize data and calculate similarity matrix again (after\n",
    "        some few ratings added)\n",
    "        \"\"\"\n",
    "        self.normalize_Y()\n",
    "        self.similarity()\n",
    "\n",
    "    def fit(self):\n",
    "        self.refresh()\n",
    "\n",
    "    def __pred(self, u, i, normalized = 1):\n",
    "        \"\"\"\n",
    "        predict the rating of user u for item i (normalized)\n",
    "        if you need the un\n",
    "        \"\"\"\n",
    "        # Step 1: find all users who rated i\n",
    "        ids = np.where(self.Y_data[:, 1] == i)[0].astype(np.int32)\n",
    "        # Step 2:\n",
    "        users_rated_i = (self.Y_data[ids, 0]).astype(np.int32)\n",
    "        users_rated_i_to_list = [int(x) for x in users_rated_i]\n",
    "        # Step 3: find similarity btw the current user and others\n",
    "        # who already rated i\n",
    "        sim = self.S[int(u), users_rated_i_to_list]\n",
    "        # Step 4: find the k most similarity users\n",
    "        a = np.argsort(sim)[-self.k:]\n",
    "        # and the corresponding similarity levels\n",
    "        nearest_s = sim[a]\n",
    "        # How did each of 'near' users rated item i\n",
    "        r = self.Ybar[i, users_rated_i[a]]\n",
    "        if normalized:\n",
    "            # add a small number, for instance, 1e-8, to avoid dividing by 0\n",
    "            return (r*nearest_s)[0]/(np.abs(nearest_s).sum() + 1e-8)\n",
    "        return (r*nearest_s)[0]/(np.abs(nearest_s).sum() + 1e-8) + self.mu[int(u)]\n",
    "\n",
    "\n",
    "    def pred(self, u, i, normalized = 1):\n",
    "        \"\"\"\n",
    "        predict the rating of user u for item i (normalized)\n",
    "        if you need the un\n",
    "        \"\"\"\n",
    "        if self.uuCF: return self.__pred(u, i, normalized)\n",
    "        return self.__pred(i, u, normalized)\n",
    "\n",
    "    def recommend(self, u, normalized=1):\n",
    "        \"\"\"\n",
    "        Determine all items should be recommended for user u. (uuCF = 1)\n",
    "        or all users who might have interest in item u (uuCF = 0)\n",
    "        The decision is made based on all i such that:\n",
    "        self.pred(u, i) > 0. Suppose we are considering items which\n",
    "        have not been rated by u yet.\n",
    "        \"\"\"\n",
    "        ids = np.where(self.Y_data[:, 0] == u)[0]\n",
    "        items_rated_by_u = self.Y_data[ids, 1].tolist()\n",
    "        recommended_items = []\n",
    "\n",
    "        for i in self.items_id:\n",
    "            if i not in items_rated_by_u:\n",
    "                rating = self.__pred(u, i)\n",
    "                if rating > 0:\n",
    "                    recommended_items.append((i, rating))\n",
    "\n",
    "        # Sort recommended items based on ratings in descending order\n",
    "        recommended_items.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # Return only the top 5 items\n",
    "        top5_recommendations = [item[0] + 1 for item in recommended_items[:5]]\n",
    "\n",
    "        return top5_recommendations\n",
    "\n",
    "    def print_recommendation(self):\n",
    "        \"\"\"\n",
    "        print all items which should be recommended for each user\n",
    "        \"\"\"\n",
    "        print('Recommendation: ')\n",
    "        for u in range(self.n_users):\n",
    "            recommended_items = self.recommend(u)\n",
    "            if self.uuCF:\n",
    "                print('Recommend item(s):', recommended_items, 'to user', u)\n",
    "            else:\n",
    "                print('Recommend item', u, 'to user(s) : ', recommended_items)\n",
    "\n",
    "        # def recommend(self, u, normalized = 1):\n",
    "    #     \"\"\"\n",
    "    #     Determine all items should be recommended for user u. (uuCF =1)\n",
    "    #     or all users who might have interest on item u (uuCF = 0)\n",
    "    #     The decision is made based on all i such that:\n",
    "    #     self.pred(u, i) > 0. Suppose we are considering items which\n",
    "    #     have not been rated by u yet.\n",
    "    #     \"\"\"\n",
    "    #     ids = np.where(self.Y_data[:, 0] == u)[0]\n",
    "    #     items_rated_by_u = self.Y_data[ids, 1].tolist()\n",
    "    #     recommended_items = []\n",
    "    #     for i in range(self.n_items):\n",
    "    #         if i not in items_rated_by_u:\n",
    "    #             rating = self.__pred(u, i)\n",
    "    #             if rating > 0:\n",
    "    #                 recommended_items.append(i)\n",
    "\n",
    "    #     return recommended_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f55f6a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-user CF, RMSE = 1.0691719142687672\n"
     ]
    }
   ],
   "source": [
    "rscf = CF(rate_train, k = 30, uuCF = 1)\n",
    "rscf.fit()\n",
    "\n",
    "n_tests = rate_test.shape[0]\n",
    "SE = 0 # squared error\n",
    "for n in range(n_tests):\n",
    "    pred = rscf.pred(int(rate_test[n, 0]), int(rate_test[n, 1]), normalized = 0)\n",
    "    SE += (pred - rate_test[n, 2])**2\n",
    "\n",
    "RMSE = np.sqrt(SE/n_tests)\n",
    "print('User-user CF, RMSE =', RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70744e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computing_collab_user_pred_results(rates):\n",
    "    preds = []\n",
    "    n = rates.shape[0]\n",
    "    for i in range(n):\n",
    "        pred = rscf.pred(rates[i, 0], rates[i, 1])\n",
    "        preds.append(pred)\n",
    "    return np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aff90b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.97732068 3.91047852 3.0146319  ... 3.3506872  3.98721166 4.3997263 ]\n",
      "4795\n"
     ]
    }
   ],
   "source": [
    "collab_pred = computing_collab_user_pred_results(rate_test)\n",
    "print(collab_pred)\n",
    "print(len(collab_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cd198c",
   "metadata": {},
   "source": [
    "## Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50567a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF(object):\n",
    "    \"\"\"docstring for CF\"\"\"\n",
    "    def __init__(self, Y_data, K, lam = 0.1, Xinit = None, Winit = None, \n",
    "            learning_rate = 0.5, max_iter = 1000, print_every = 100, user_based = 1):\n",
    "        self.Y_raw_data = Y_data\n",
    "        self.K = K\n",
    "        # regularization parameter\n",
    "        self.lam = lam\n",
    "        # learning rate for gradient descent\n",
    "        self.learning_rate = learning_rate\n",
    "        # maximum number of iterations\n",
    "        self.max_iter = max_iter\n",
    "        # print results after print_every iterations\n",
    "        self.print_every = print_every\n",
    "        # user-based or item-based\n",
    "        self.user_based = user_based\n",
    "        # number of users, items, and ratings. Remember to add 1 since id starts from 0\n",
    "        self.n_users = int(np.max(Y_data[:, 0])) + 1 \n",
    "        self.n_items = int(np.max(Y_data[:, 1])) + 1\n",
    "        self.n_ratings = Y_data.shape[0]\n",
    "        self.items_id = [int(item) for item in np.unique(Y_data[:, 1])]\n",
    "\n",
    "        if Xinit is None: # new\n",
    "            self.X = np.random.randn(self.n_items, K)\n",
    "        else: # or from saved data\n",
    "            self.X = Xinit \n",
    "        \n",
    "        if Winit is None: \n",
    "            self.W = np.random.randn(K, self.n_users)\n",
    "        else: # from daved data\n",
    "            self.W = Winit\n",
    "            \n",
    "        # normalized data, update later in normalized_Y function\n",
    "        self.Y_data_n = self.Y_raw_data.copy()\n",
    "\n",
    "\n",
    "    def normalize_Y(self):\n",
    "        if self.user_based:\n",
    "            user_col = 0\n",
    "            item_col = 1\n",
    "            n_objects = self.n_users\n",
    "\n",
    "        # if we want to normalize based on item, just switch first two columns of data\n",
    "        else: # item bas\n",
    "            user_col = 1\n",
    "            item_col = 0 \n",
    "            n_objects = self.n_items\n",
    "\n",
    "        users = self.Y_raw_data[:, user_col] \n",
    "        self.mu = np.zeros((n_objects,))\n",
    "        for n in range(n_objects):\n",
    "            # row indices of rating done by user n\n",
    "            # since indices need to be integers, we need to convert\n",
    "            ids = np.where(users == n)[0].astype(np.int32)\n",
    "            # indices of all ratings associated with user n\n",
    "            item_ids = self.Y_data_n[ids, item_col] \n",
    "            # and the corresponding ratings \n",
    "            ratings = self.Y_data_n[ids, 2]\n",
    "            # take mean\n",
    "            m = np.mean(ratings) \n",
    "            if np.isnan(m):\n",
    "                m = 0 # to avoid empty array and nan value\n",
    "            self.mu[n] = m\n",
    "            # normalize\n",
    "            self.Y_data_n[ids, 2] = ratings - self.mu[n]\n",
    "            \n",
    "    def loss(self):\n",
    "        L = 0 \n",
    "        for i in range(self.n_ratings):\n",
    "            # user, item, rating\n",
    "            n, m, rate = int(self.Y_data_n[i, 0]), int(self.Y_data_n[i, 1]), self.Y_data_n[i, 2]\n",
    "            L += 0.5*(rate - self.X[m, :].dot(self.W[:, n]))**2\n",
    "\n",
    "        # take average\n",
    "        L /= self.n_ratings\n",
    "        # regularization, don't ever forget this \n",
    "        L += 0.5*self.lam*(np.linalg.norm(self.X, 'fro') + np.linalg.norm(self.W, 'fro'))\n",
    "        return L \n",
    "\n",
    "    def get_items_rated_by_user(self, user_id):\n",
    "        \"\"\"\n",
    "        get all items which are rated by user user_id, and the corresponding ratings\n",
    "        \"\"\"\n",
    "        ids = np.where(self.Y_data_n[:,0] == user_id)[0] \n",
    "        item_ids = self.Y_data_n[ids, 1].astype(np.int32) # indices need to be integers\n",
    "        ratings = self.Y_data_n[ids, 2]\n",
    "        return (item_ids, ratings)\n",
    "        \n",
    "        \n",
    "    def get_users_who_rate_item(self, item_id):\n",
    "        \"\"\"\n",
    "        get all users who rated item item_id and get the corresponding ratings\n",
    "        \"\"\"\n",
    "        ids = np.where(self.Y_data_n[:,1] == item_id)[0] \n",
    "        user_ids = self.Y_data_n[ids, 0].astype(np.int32)\n",
    "        ratings = self.Y_data_n[ids, 2]\n",
    "        return (user_ids, ratings)\n",
    "    \n",
    "    def updateX(self):\n",
    "        for m in range(self.n_items):\n",
    "            user_ids, ratings = self.get_users_who_rate_item(m)\n",
    "            Wm = self.W[:, user_ids]\n",
    "            # gradient\n",
    "            grad_xm = -(ratings - self.X[m, :].dot(Wm)).dot(Wm.T)/self.n_ratings + \\\n",
    "                                               self.lam*self.X[m, :]\n",
    "            self.X[m, :] -= self.learning_rate*grad_xm.reshape((self.K,))\n",
    "    \n",
    "    def updateW(self):\n",
    "        for n in range(self.n_users):\n",
    "            item_ids, ratings = self.get_items_rated_by_user(n)\n",
    "            Xn = self.X[item_ids, :]\n",
    "            # gradient\n",
    "            grad_wn = -Xn.T.dot(ratings - Xn.dot(self.W[:, n]))/self.n_ratings + \\\n",
    "                        self.lam*self.W[:, n]\n",
    "            self.W[:, n] -= self.learning_rate*grad_wn.reshape((self.K,))\n",
    "\n",
    "    def fit(self):\n",
    "        self.normalize_Y()\n",
    "        for it in range(self.max_iter):\n",
    "            self.updateX()\n",
    "            self.updateW()\n",
    "            if (it + 1) % self.print_every == 0:\n",
    "                rmse_train = self.evaluate_RMSE(self.Y_raw_data)\n",
    "                print('iter =', it + 1, ', loss =', self.loss(), ', RMSE train =', rmse_train)\n",
    "    \n",
    "    def pred(self, u, i):\n",
    "        \"\"\" \n",
    "        predict the rating of user u for item i \n",
    "        if you need the un\n",
    "        \"\"\"\n",
    "        u = int(u)\n",
    "        i = int(i)\n",
    "        if self.user_based:\n",
    "            bias = self.mu[u]\n",
    "        else: \n",
    "            bias = self.mu[i]\n",
    "        pred = self.X[i, :].dot(self.W[:, u]) + bias \n",
    "        # truncate if results are out of range [0, 5]\n",
    "        if pred < 0:\n",
    "            return 0 \n",
    "        if pred > 5: \n",
    "            return 5 \n",
    "        return pred \n",
    "        \n",
    "    \n",
    "    def pred_for_user(self, user_id):\n",
    "        \"\"\"\n",
    "        predict ratings one user give all unrated items\n",
    "        \"\"\"\n",
    "        ids = np.where(self.Y_data_n[:, 0] == user_id)[0]\n",
    "        items_rated_by_u = self.Y_data_n[ids, 1].tolist()              \n",
    "        \n",
    "        y_pred = self.X.dot(self.W[:, user_id]) + self.mu[user_id]\n",
    "        predicted_ratings= []\n",
    "        for i in self.items_id:\n",
    "            if i not in items_rated_by_u:\n",
    "                predicted_ratings.append((i, y_pred[i]))\n",
    "        \n",
    "        return predicted_ratings\n",
    "    \n",
    "    def evaluate_RMSE(self, rate_test):\n",
    "        n_tests = rate_test.shape[0]\n",
    "        SE = 0 # squared error\n",
    "        for n in range(n_tests):\n",
    "            pred = self.pred(rate_test[n, 0], rate_test[n, 1])\n",
    "            SE += (pred - rate_test[n, 2])**2 \n",
    "\n",
    "        RMSE = np.sqrt(SE/n_tests)\n",
    "        return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47145464",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter = 5 , loss = 47.102899304331885 , RMSE train = 1.5270995582522782\n",
      "iter = 10 , loss = 31.577942882778167 , RMSE train = 1.1386008319352328\n",
      "iter = 15 , loss = 21.434618219778233 , RMSE train = 0.999510594317888\n",
      "iter = 20 , loss = 14.642208458386989 , RMSE train = 0.9651233869488713\n",
      "iter = 25 , loss = 10.058548166846684 , RMSE train = 0.9576240690845343\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'rs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m rsmt\u001b[38;5;241m.\u001b[39mfit()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# evaluate on train data\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# evaluate on test data\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m RMSE \u001b[38;5;241m=\u001b[39m \u001b[43mrs\u001b[49m\u001b[38;5;241m.\u001b[39mevaluate_RMSE(rate_test)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mUser-based MF, RMSE =\u001b[39m\u001b[38;5;124m'\u001b[39m, RMSE)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rs' is not defined"
     ]
    }
   ],
   "source": [
    "rsmt = MF(rate_train, K = 10, lam = .1, print_every = 5, \n",
    "    learning_rate = 0.75, max_iter = 25, user_based = 1)\n",
    "rsmt.fit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "567967f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User-based MF, RMSE = 0.9792598761558395\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test data\n",
    "RMSE = rsmt.evaluate_RMSE(rate_test)\n",
    "print('\\nUser-based MF, RMSE =', RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99c0e16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computing_matrix_pred_results(rates):\n",
    "    preds = []\n",
    "    n = rates.shape[0]\n",
    "    for i in range(n):\n",
    "        pred = rsmt.pred(rates[i, 0], rates[i, 1])\n",
    "        preds.append(pred)\n",
    "    return np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "498dea23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.31510679 3.49335394 3.46323915 ... 4.06268202 4.03533894 4.47315287]\n",
      "4795\n"
     ]
    }
   ],
   "source": [
    "mat_pred = computing_matrix_pred_results(rate_test)\n",
    "print(mat_pred)## Find best weight to combine two algorithms linearly\n",
    "print(len(mat_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e8ac01",
   "metadata": {},
   "source": [
    "## Find best weight to combine two algorithms linearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f53882ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "771dceb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "chart_val = []\n",
    "\n",
    "w = np.linspace(0,1,100)\n",
    "\n",
    "for i in w:\n",
    "    hybrid_pred = mat_pred*i + collab_pred*(1-i)\n",
    "    rmse = np.sqrt(np.mean((hybrid_pred - np.array(rate_test[:, 2]))**2))\n",
    "    chart_val.append([i, rmse])\n",
    "\n",
    "chart_val_np = np.array(chart_val)\n",
    "plt.xlabel('Weight (i)')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Hybrid Model RMSE')\n",
    "\n",
    "# Find the minimum point on the curve\n",
    "min_index = np.argmin(chart_val_np[:, 1])\n",
    "min_point = chart_val_np[min_index]\n",
    "\n",
    "# Annotate the minimum point on the plot with the weight (i)\n",
    "plt.annotate(f'Minimum RMSE\\nWeight (i): {min_point[0]:.4f}\\nRMSE: {min_point[1]:.4f}', xy=min_point, xytext=(0.5, 50),\n",
    "             textcoords='offset points', arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3\"))\n",
    "plt.plot(chart_val_np[:, 0], chart_val_np[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a244404",
   "metadata": {},
   "source": [
    "We can see that the RMSE is smaller than both Collaborative Filtering (User-User) & Matrix Factorization models slightly.\n",
    "The minimum RMSE is 0.9312 when weight is 0.6364\n",
    "(when the RMSE for test train for two algorithms are 1.069, 0.9792)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
